{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d28c54e3",
   "metadata": {},
   "source": [
    "Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ed1356af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8e80f",
   "metadata": {},
   "source": [
    "Files: all three files, country, datadict, indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44354d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDICATOR_ID</th>\n",
       "      <th>COUNTRY_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>MAGNITUDE</th>\n",
       "      <th>QUALIFIER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXPGDP.TOT</td>\n",
       "      <td>AGO</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.03229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXPGDP.TOT</td>\n",
       "      <td>ALB</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.08757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXPGDP.TOT</td>\n",
       "      <td>ALB</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.15412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXPGDP.TOT</td>\n",
       "      <td>ARE</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.47252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXPGDP.TOT</td>\n",
       "      <td>ARE</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.67523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4250</th>\n",
       "      <td>RESDEN.INHAB.TFTE</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>1997</td>\n",
       "      <td>54.29949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4251</th>\n",
       "      <td>RESDEN.INHAB.TFTE</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>1998</td>\n",
       "      <td>56.42220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4252</th>\n",
       "      <td>RESDEN.INHAB.TFTE</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>1999</td>\n",
       "      <td>55.79382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>RESDEN.INHAB.TFTE</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>2008</td>\n",
       "      <td>41.90146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4254</th>\n",
       "      <td>RESDEN.INHAB.TFTE</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2012</td>\n",
       "      <td>95.12530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4255 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           INDICATOR_ID COUNTRY_ID  YEAR     VALUE  MAGNITUDE QUALIFIER\n",
       "0            EXPGDP.TOT        AGO  2016   0.03229        NaN       NaN\n",
       "1            EXPGDP.TOT        ALB  2007   0.08757        NaN       NaN\n",
       "2            EXPGDP.TOT        ALB  2008   0.15412        NaN       NaN\n",
       "3            EXPGDP.TOT        ARE  2011   0.47252        NaN       NaN\n",
       "4            EXPGDP.TOT        ARE  2014   0.67523        NaN       NaN\n",
       "...                 ...        ...   ...       ...        ...       ...\n",
       "4250  RESDEN.INHAB.TFTE        ZMB  1997  54.29949        NaN       NaN\n",
       "4251  RESDEN.INHAB.TFTE        ZMB  1998  56.42220        NaN       NaN\n",
       "4252  RESDEN.INHAB.TFTE        ZMB  1999  55.79382        NaN       NaN\n",
       "4253  RESDEN.INHAB.TFTE        ZMB  2008  41.90146        NaN       NaN\n",
       "4254  RESDEN.INHAB.TFTE        ZWE  2012  95.12530        NaN       NaN\n",
       "\n",
       "[4255 rows x 6 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#switch between the files \n",
    "\n",
    "#df = pd.read_excel('SDG_DATA_NATIONAL.xlsx') \n",
    "#df = pd.read_csv(r'C:\\Users\\Norah\\Downloads\\OPRI (1)\\OPRI_DATA_NATIONAL.csv', low_memory=False)\n",
    "df = pd.read_excel('SCN-SDG_DATA_NATIONAL.xlsx') #EXPGDP.TOT\n",
    "country = pd.read_excel('UIS UNESCO Country.xlsx', sheet_name='Country') \n",
    "datadict = pd.read_excel('UIS UNESCO Country.xlsx', sheet_name='DataDict')\n",
    "#remember to switch sheets here too\n",
    "indicators = pd.read_excel('UIS UNESCO Country.xlsx', sheet_name='SCN-SDG')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9457f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "formulatables = {\n",
    "    'EdPriEnrollHeadCountTtl', 'EdPriEnrollHeadcountFem', 'EdSecLowerEnrollHeadcountTotal', 'EdSecLowerEnrollHeadcountFemale',\n",
    "    'EdSecUpperEnrollHeadcountTotal', 'EdSecUpperEnrollHeadcountFemale', 'EdSecEnrNoTot', 'EdSecEnrNoFem',\n",
    "    'EdTerEnrollHeadcountTotal', 'EdTerEnrollHeadcountFem', 'EdPriEnrollHeadcountMal', 'EdSecLowerEnrollHeadcountMale',\n",
    "    'EdSecUpperEnrollHeadCountMale', 'EdSecEnrNoMal', 'EdTerEnrISCED6HdctMale', 'EdTerEnrollHeadcountMale',\n",
    "    'EdTerEnrISCED6HdctFem', 'EdTerEnrISCED6HdctTot'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05428791",
   "metadata": {},
   "source": [
    "SDG + SCN-SDG + OPRI TABLES (no calculation with indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "76672b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE SQL: CREATE TABLE 'SeriesR&DGovt%GDP' (Country VARCHAR(255), FIPS_CODE VARCHAR(255), \"1996\" DOUBLE(53), \"1997\" DOUBLE(53), \"1998\" DOUBLE(53), \"1999\" DOUBLE(53), \"2000\" DOUBLE(53), \"2001\" DOUBLE(53), \"2002\" DOUBLE(53), \"2003\" DOUBLE(53), \"2004\" DOUBLE(53), \"2005\" DOUBLE(53), \"2006\" DOUBLE(53), \"2007\" DOUBLE(53), \"2008\" DOUBLE(53), \"2009\" DOUBLE(53), \"2010\" DOUBLE(53), \"2011\" DOUBLE(53), \"2012\" DOUBLE(53), \"2013\" DOUBLE(53), \"2014\" DOUBLE(53), \"2015\" DOUBLE(53), \"2016\" DOUBLE(53), \"2017\" DOUBLE(53), \"2018\" DOUBLE(53), \"2019\" DOUBLE(53), \"2020\" DOUBLE(53), \"2021\" DOUBLE(53), \"2022\" DOUBLE(53), \"2023\" DOUBLE(53), \"Earliest\" DOUBLE(53), \"MostRecent\" DOUBLE(53))\n",
      "FINAL columns for SeriesR&DGovt%GDP: Index([   'Country',  'FIPS_CODE',         1996,         1997,         1998,\n",
      "               1999,         2000,         2001,         2002,         2003,\n",
      "               2004,         2005,         2006,         2007,         2008,\n",
      "               2009,         2010,         2011,         2012,         2013,\n",
      "               2014,         2015,         2016,         2017,         2018,\n",
      "               2019,         2020,         2021,         2022,         2023,\n",
      "         'Earliest', 'MostRecent'],\n",
      "      dtype='object')\n",
      "Imported: SeriesR&DGovt%GDP\n"
     ]
    }
   ],
   "source": [
    "def parse_years(year_str):\n",
    "    if not year_str or pd.isnull(year_str):\n",
    "        return []\n",
    "    years = set()\n",
    "    for part in str(year_str).split(','):\n",
    "        part = part.strip()\n",
    "        if '-' in part:\n",
    "            start, end = part.split('-')\n",
    "            years.update(range(int(start), int(end) + 1))\n",
    "        elif part.isdigit():\n",
    "            years.add(int(part))\n",
    "    return sorted(years)\n",
    "\n",
    "conn = sqlite3.connect(r'C:\\IFs\\RUNFILES\\IFsDataImport - Copy (5) - Copy.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for _, row in indicators.iterrows():\n",
    "    indicator_id = str(row['INDICATOR_ID'])\n",
    "    table_name = str(row['Variable'])\n",
    "    sql_table_name = f\"Series{table_name}\"\n",
    "\n",
    "    dec_places = datadict.loc[datadict['Variable'] == table_name, 'Decimal Places']\n",
    "    dec_places = int(dec_places.iloc[0]) if not dec_places.empty and pd.notnull(dec_places.iloc[0]) else 4\n",
    "\n",
    "    df1 = df[df['INDICATOR_ID'] == indicator_id].copy()\n",
    "    if table_name in formulatables:\n",
    "        df1['VALUE'] = df1['VALUE'] * 0.000001\n",
    "\n",
    "    df2 = df1.drop(columns=['INDICATOR_ID', 'MAGNITUDE', 'QUALIFIER'])\n",
    "    df2 = df2.pivot(index=\"COUNTRY_ID\", columns=\"YEAR\", values=\"VALUE\")\n",
    "    #to ensure year columns are int bc some issues in OPRI\n",
    "    df2.columns = [int(float(col)) for col in df2.columns]\n",
    "    if len(df2.columns) > 0:\n",
    "        min_year = min(df2.columns)\n",
    "        max_year = max(df2.columns)\n",
    "        intended_years = list(range(min_year, max_year + 1))\n",
    "    else:\n",
    "        intended_years = []\n",
    "\n",
    "    dt = country.merge(df2.reset_index(), on='COUNTRY_ID', how='left')\n",
    "    dt = dt.drop(columns='COUNTRY_ID')\n",
    "    dt = dt.rename(columns={'IFs Country': 'Country'})\n",
    "\n",
    "    dt = dt.reindex(columns=['Country', 'FIPS_CODE'] + intended_years)\n",
    "\n",
    "    if intended_years:\n",
    "        dt['Earliest'] = dt[intended_years].bfill(axis=1).iloc[:, 0]\n",
    "        dt['MostRecent'] = dt[intended_years].ffill(axis=1).iloc[:, -1]\n",
    "        dt[intended_years + ['Earliest', 'MostRecent']] = dt[intended_years + ['Earliest', 'MostRecent']].round(dec_places)\n",
    "    else:\n",
    "        dt['Earliest'] = np.nan\n",
    "        dt['MostRecent'] = np.nan\n",
    "\n",
    "    columns_sql = ['Country VARCHAR(255)', 'FIPS_CODE VARCHAR(255)']\n",
    "    columns_sql += [f'\"{col}\" DOUBLE(53)' for col in intended_years + ['Earliest', 'MostRecent']]\n",
    "    create_table_sql = f\"CREATE TABLE '{sql_table_name}' ({', '.join(columns_sql)})\"\n",
    "    print(\"CREATE TABLE SQL:\", create_table_sql)\n",
    "\n",
    "    cursor.execute(f'DROP TABLE IF EXISTS \\\"{sql_table_name}\\\"')\n",
    "    cursor.execute(create_table_sql)\n",
    "\n",
    "    dt = dt[['Country', 'FIPS_CODE'] + intended_years + ['Earliest', 'MostRecent']]\n",
    "\n",
    "    print(f\"FINAL columns for {sql_table_name}:\", dt.columns)\n",
    "    dt.to_sql(sql_table_name, conn, if_exists='append', index=False)\n",
    "    print(f\"Imported: {sql_table_name}\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291896df",
   "metadata": {},
   "source": [
    "Formulas SDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4e410051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Norah\\Downloads\\SDG (2)\\SDG_DATA_NATIONAL.csv\", low_memory=False)\n",
    "conn = sqlite3.connect(r'C:\\IFs\\RUNFILES\\IFsDataImport - Copy (5) - Copy.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def process_sum_table(ind_ids, table_name, min_year=None, max_year=None):\n",
    "    g2 = df[df['INDICATOR_ID'] == ind_ids[0]]\n",
    "    g3 = df[df['INDICATOR_ID'] == ind_ids[1]]\n",
    "    dec_places = datadict.loc[datadict['Variable'] == table_name, 'Decimal Places']\n",
    "    dec_places = int(dec_places.iloc[0]) if not dec_places.empty and pd.notnull(dec_places.iloc[0]) else 4\n",
    "\n",
    "    g2 = g2.drop(columns=['INDICATOR_ID', 'MAGNITUDE', 'QUALIFIER'], errors='ignore')\n",
    "    g3 = g3.drop(columns=['INDICATOR_ID', 'MAGNITUDE', 'QUALIFIER'], errors='ignore')\n",
    "\n",
    "\n",
    "    pivot1 = g2.pivot(index='COUNTRY_ID', columns='YEAR', values='VALUE')\n",
    "    pivot2 = g3.pivot(index='COUNTRY_ID', columns='YEAR', values='VALUE')\n",
    "    g2g3 = pivot1.add(pivot2, fill_value=0)\n",
    "\n",
    "    g2g3 = country.merge(g2g3.reset_index(), on='COUNTRY_ID', how='left').drop(columns='COUNTRY_ID')\n",
    "    g2g3.rename(columns={'IFs Country': 'Country'}, inplace=True)\n",
    "\n",
    "    all_years = set(pivot1.columns).union(set(pivot2.columns))\n",
    "    if not all_years:\n",
    "        print(f\"Skipping {table_name}: No data for indicators {ind_ids}\")\n",
    "        return\n",
    "    if min_year is None:\n",
    "        min_year = int(min(all_years))\n",
    "    if max_year is None:\n",
    "        max_year = int(max(all_years))\n",
    "    full_years = list(range(min_year, max_year + 1))\n",
    "    for year in full_years:\n",
    "        if year not in g2g3.columns:\n",
    "            g2g3[year] = np.nan\n",
    "    year_columns = sorted(full_years)\n",
    "    g2g3 = g2g3[['Country', 'FIPS_CODE'] + year_columns]\n",
    "\n",
    "\n",
    "    year_columns = [col for col in g2g3.columns if isinstance(col, int) or (isinstance(col, str) and col.isdigit())]\n",
    "    g2g3['Earliest'] = g2g3[year_columns].bfill(axis=1).iloc[:, 0]\n",
    "    g2g3['MostRecent'] = g2g3[year_columns].ffill(axis=1).iloc[:, -1]\n",
    "    g2g3[year_columns + ['Earliest', 'MostRecent']] = g2g3[year_columns + ['Earliest', 'MostRecent']].round(dec_places)\n",
    "\n",
    "    columns_sql = ['Country VARCHAR(255)', 'FIPS_CODE VARCHAR(255)'] + \\\n",
    "                  [f'\"{col}\" DOUBLE(53)' for col in year_columns + ['Earliest', 'MostRecent']]\n",
    "    create_table_sql = f\"CREATE TABLE '{table_name}' ({', '.join(columns_sql)})\"\n",
    "\n",
    "    cursor.execute(f'DROP TABLE IF EXISTS \"{table_name}\"')\n",
    "    cursor.execute(create_table_sql)\n",
    "    g2g3.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "\n",
    "tables_info = [\n",
    "    (['READ.G2.GPIA', 'READ.G3.GPIA'], 'SeriesEdPri2and3ParityGenderRead'),\n",
    "    (['READ.G2.LPIA', 'READ.G3.LPIA'], 'SeriesEdPri2and3ParityRurUrbRead'),\n",
    "    (['READ.G2.WPIA', 'READ.G3.WPIA'], 'SeriesEdPri2and3ParitySocioeconRead'),\n",
    "    (['MATH.G2.GPIA', 'MATH.G3.GPIA'], 'SeriesEdPri2and3ParityGenderMath'),\n",
    "    (['MATH.G2.LPIA', 'MATH.G3.LPIA'], 'SeriesEdPri2and3ParityRurUrbMath'),\n",
    "    (['MATH.G2.WPIA', 'MATH.G3.WPIA'], 'SeriesEdPri2and3ParitySocioeconMath'),\n",
    "]\n",
    "\n",
    "for indicators, name in tables_info:\n",
    "    process_sum_table(indicators, name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95774ee",
   "metadata": {},
   "source": [
    "Formulas OPRI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efb1c75",
   "metadata": {},
   "source": [
    "Dividing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "441f9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Norah\\Downloads\\OPRI (1)\\OPRI_DATA_NATIONAL.csv', low_memory=False)\n",
    "conn = sqlite3.connect(r'C:\\IFs\\RUNFILES\\IFsDataImport - Copy (5) - Copy.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def process_ratio(inop, inri, table_name, min_year=None, max_year=None):\n",
    "    op = df[df['INDICATOR_ID'] == inop].drop(columns=['INDICATOR_ID', 'MAGNITUDE', 'QUALIFIER'], errors='ignore')\n",
    "    ri = df[df['INDICATOR_ID'] == inri].drop(columns=['INDICATOR_ID', 'MAGNITUDE', 'QUALIFIER'], errors='ignore')\n",
    "    \n",
    "    dec_places = datadict.loc[datadict['Variable'] == table_name, 'Decimal Places']\n",
    "    dec_places = int(dec_places.iloc[0]) if not dec_places.empty and pd.notnull(dec_places.iloc[0]) else 4\n",
    "\n",
    "    pivot1 = op.pivot(index='COUNTRY_ID', columns='YEAR', values='VALUE')\n",
    "    pivot2 = ri.pivot(index='COUNTRY_ID', columns='YEAR', values='VALUE')\n",
    "    \n",
    "    all_years = set(pivot1.columns).union(set(pivot2.columns))\n",
    "    if not all_years:\n",
    "        print(f\"Skipping {table_name}: No data for operands {inop} and {inri}\")\n",
    "        return\n",
    "    if min_year is None:\n",
    "        min_year = int(min(all_years))\n",
    "    if max_year is None:\n",
    "        max_year = int(max(all_years))\n",
    "    full_years = list(range(min_year, max_year + 1))\n",
    "    \n",
    "    for year in full_years:\n",
    "        if year not in pivot1.columns:\n",
    "            pivot1[year] = np.nan\n",
    "        if year not in pivot2.columns:\n",
    "            pivot2[year] = np.nan\n",
    "    pivot1 = pivot1[sorted(pivot1.columns)]\n",
    "    pivot2 = pivot2[sorted(pivot2.columns)]\n",
    "\n",
    "    opri = pivot1 / pivot2\n",
    "    opri = country.merge(opri.reset_index(), on='COUNTRY_ID', how='left').drop(columns='COUNTRY_ID')\n",
    "    opri = opri.rename(columns={'IFs Country': 'Country'})\n",
    "    opri = opri.rename(columns={'FIPS':'FIPS_CODE'})\n",
    "    for year in full_years:\n",
    "        if year not in opri.columns:\n",
    "            opri[year] = np.nan\n",
    "    year_cols = sorted([col for col in opri.columns if str(col).isdigit()], key=int)\n",
    "    opri = opri[['Country', 'FIPS_CODE'] + year_cols]\n",
    "    opri['Earliest'] = opri[year_cols].bfill(axis=1).iloc[:, 0]\n",
    "    opri['MostRecent'] = opri[year_cols].ffill(axis=1).iloc[:, -1]\n",
    "    opri[year_cols + ['Earliest', 'MostRecent']] = opri[year_cols + ['Earliest', 'MostRecent']].round(dec_places)\n",
    "    \n",
    "    columns_sql = ['Country VARCHAR(255)', 'FIPS_CODE VARCHAR(255)'] + [f'\"{col}\" DOUBLE(53)' for col in year_cols + ['Earliest', 'MostRecent']]\n",
    "    cursor.execute(f'DROP TABLE IF EXISTS \"{table_name}\"')\n",
    "    cursor.execute(f\"CREATE TABLE '{table_name}' ({', '.join(columns_sql)})\")\n",
    "    opri.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "    \n",
    "tasks = [\n",
    "    ('20062', '20162', 'SeriesPupilTeacherRatioUISPrimary'),\n",
    "    ('20062', '20162', 'SeriesEDPriPTR'),\n",
    "    ('20082', '20182', 'SeriesPupilTeacherRatioUISSecondary'),\n",
    "    ('X.USCONST.02.FSGOV', 'X.USCONST.FSGOV', 'SeriesEdExpPrePri%EducTot'),\n",
    "    ('X.USCONST.1.FSGOV', 'X.USCONST.FSGOV', 'SeriesEdExpPri%EducTot'),\n",
    "    ('X.USCONST.2.FSGOV', 'X.USCONST.FSGOV', 'SeriesEdExpSecLowr%EducTot'),\n",
    "    ('X.USCONST.2T3.FSGOV', 'X.USCONST.FSGOV', 'SeriesEdExpSec%EducTot'),\n",
    "    ('20062', '20162', 'SeriesEdExpSecUppr%EducTot'),\n",
    "    ('X.USCONST.5T8.FSGOV', 'X.USCONST.FSGOV', 'SeriesEdExpTer%EducTot'),\n",
    "    ('20064', '20164', 'SeriesEdSecLowrPTR')\n",
    "]\n",
    "for op, ri, table in tasks:\n",
    "    process_ratio(op, ri, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed138d5",
   "metadata": {},
   "source": [
    "Adding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f8f16df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Norah\\Downloads\\OPRI (1)\\OPRI_DATA_NATIONAL.csv', low_memory=False)\n",
    "conn = sqlite3.connect(r'C:\\IFs\\RUNFILES\\IFsDataImport - Copy (5) - Copy.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def process_indicators(indicator_ids, table_name, min_year=None, max_year=None):\n",
    "    dfs = []\n",
    "    for indicator in indicator_ids:\n",
    "        dfa = df[df['INDICATOR_ID'] == indicator].drop(columns=['INDICATOR_ID', 'MAGNITUDE', 'QUALIFIER'], errors='ignore')\n",
    "        if dfa.empty:\n",
    "            continue\n",
    "        pivoted = dfa.pivot(index='COUNTRY_ID', columns='YEAR', values='VALUE')\n",
    "        dfs.append(pivoted)\n",
    "    \n",
    "    all_years = set()\n",
    "    for d in dfs:\n",
    "        all_years.update(d.columns)\n",
    "\n",
    "    if not all_years:\n",
    "        print(f\"Skipping {table_name}: No data for indicators {indicator_ids}\")\n",
    "        return  \n",
    "\n",
    "    if min_year is None:\n",
    "        min_year = int(min(all_years))\n",
    "    if max_year is None:\n",
    "        max_year = int(max(all_years))\n",
    "    full_years = list(range(min_year, max_year + 1)) \n",
    "    \n",
    "    dec_places = datadict.loc[datadict['Variable'] == table_name, 'Decimal Places']\n",
    "    dec_places = int(dec_places.iloc[0]) if not dec_places.empty and pd.notnull(dec_places.iloc[0]) else 4\n",
    "\n",
    "    oprisum = sum(dfs)\n",
    "    oprisum = country.merge(oprisum.reset_index(), on='COUNTRY_ID', how='left').drop(columns='COUNTRY_ID')\n",
    "    oprisum = oprisum.rename(columns={'IFs Country': 'Country'})\n",
    "    for year in full_years:\n",
    "        if year not in oprisum.columns:\n",
    "            oprisum[year] = np.nan\n",
    "\n",
    "    year_columns = sorted([col for col in oprisum.columns if isinstance(col, int) or (isinstance(col, str) and str(col).isdigit())], key=lambda x: int(x))\n",
    "    oprisum = oprisum[['Country', 'FIPS_CODE'] + year_columns]\n",
    "    oprisum['Earliest'] = oprisum[year_columns].bfill(axis=1).iloc[:, 0]\n",
    "    oprisum['MostRecent'] = oprisum[year_columns].ffill(axis=1).iloc[:, -1]\n",
    "    oprisum[year_columns + ['Earliest', 'MostRecent']] = oprisum[year_columns + ['Earliest', 'MostRecent']].round(dec_places)\n",
    "\n",
    "    columns_sql = ['Country VARCHAR(255)', 'FIPS_CODE VARCHAR(255)']\n",
    "    columns_sql += [f'\"{col}\" DOUBLE(53)' for col in year_columns + ['Earliest', 'MostRecent']]\n",
    "    create_table_sql = f\"CREATE TABLE '{table_name}' ({', '.join(columns_sql)})\"\n",
    "    cursor.execute(f'DROP TABLE IF EXISTS \"{table_name}\"')\n",
    "    cursor.execute(create_table_sql)\n",
    "    oprisum.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "\n",
    "indicator_sets = {\n",
    "    'SeriesGovtEdPub%GDP': ['XGDP.02.FSGOV', 'XGDP.1.FSGOV', 'XGDP.2.FSGOV', 'XGDP.3.FSGOV', 'XGDP.4.FSGOV', 'XGDP.5T8.FSGOV'],\n",
    "    'SeriesEdExpISCED1-4TotalCur%': ['XSPENDP.1.FDPUB.FNCUR', 'XSPENDP.2.FDPUB.FNCUR', 'XSPENDP.3.FDPUB.FNCUR', 'XSPENDP.4.FDPUB.FNCUR'],\n",
    "    'SeriesEdExpISCED1-4NonSalCur%': ['XSPENDP.1.FDPUB.FNNONS', 'XSPENDP.2.FDPUB.FNNONS', 'XSPENDP.3.FDPUB.FNNONS', 'XSPENDP.4.FDPUB.FNNONS'],\n",
    "    'SeriesEdExpISCED1-4Sal%': ['XSPENDP.1.FDPUB.FNS', 'XSPENDP.2.FDPUB.FNS', 'XSPENDP.3.FDPUB.FNS', 'XSPENDP.4.FDPUB.FNS'],\n",
    "    'SeriesEdExpISCED1-4Cap': ['XSPENDP.1.FDPUB.FNCAP', 'XSPENDP.2.FDPUB.FNCAP', 'XSPENDP.3.FDPUB.FNCAP', 'XSPENDP.4.FDPUB.FNCAP'],\n",
    "    'SeriesEdTerGrads%Sci': ['FOSGP.5T8.F500', 'FOSGP.5T8.F600']\n",
    "}\n",
    "\n",
    "for table_name, indicators in indicator_sets.items():\n",
    "    process_indicators(indicators, table_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ef0bec",
   "metadata": {},
   "source": [
    "DataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5fad75c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_int_convert(val):\n",
    "    if pd.isna(val):\n",
    "        return val\n",
    "    if isinstance(val, int) and abs(val) > 2**63 - 1:\n",
    "        return str(val)\n",
    "    return val\n",
    "datadict = datadict.map(safe_int_convert)\n",
    "\n",
    "conn = sqlite3.connect(r'C:\\IFs\\RUNFILES\\IFsDataImport - Copy (5) - Copy.db')\n",
    "cursor = conn.cursor()\n",
    "table_name = 'DataDict'\n",
    "datadict.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
